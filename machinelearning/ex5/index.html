<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <title>
    ex5.Regularized Linear Regression and Bias v.s.Variance // Hello world!
  </title>

  <link href="http://gmpg.org/xfn/11" rel="profile">
<meta http-equiv="content-type" content="text/html; charset=utf-8">


<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="generator" content="Hugo 0.16" />

  <meta property="og:title" content="ex5.Regularized Linear Regression and Bias v.s.Variance" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="https://shiweihou.github.io/machinelearning/ex5/" />


  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/base-min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
  
  
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css">
  
  

  <link rel="stylesheet" href="https://shiweihou.github.io//css/redlounge.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
  <link href='//fonts.googleapis.com/css?family=Raleway:400,200,100,700,300,500,600,800' rel='stylesheet' type='text/css'>
  <link href='//fonts.googleapis.com/css?family=Libre+Baskerville:400,700,400italic' rel='stylesheet' type='text/css'>

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Hello world!" />

    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/tomorrow-night-bright.min.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  

  

  

  
</head>

<body>
	

	<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
  <div class="header">
    

	
	  <img src="/img/1.jpg" class="sidebarphoto">
	

    <h1 class="brand-title">Matthew</h1>
    <h2 class="brand-tagline">积跬步，至千里</h2>

    <nav class="nav">
      <ul class="nav-list">
        <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://shiweihou.github.io/">Home</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/cplusplus/">C&#43;&#43;</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/redis/">Redis</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/lintcode/">刷题</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/machinelearning/">机器学习</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/pointcloud/">点云</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="/algorithm/">编程</a></li>
        
      </ul>
    </nav>

    

  </div>
</div>

	
	

    <div class="content pure-u-1 pure-u-md-3-4">
		<a name="top"></a>
		

		
			
		    <div id="toc" class="pure-u-1 pure-u-md-1-4">
				<small class="toc-label">Contents</small>
		   	 	<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#regularized-linear-regression-cost-function-and-gradient">Regularized linear regression cost function and Gradient</a></li>
<li><a href="#learning-curves">Learning curves</a></li>
<li><a href="#polynomial-regression">Polynomial regression</a></li>
<li><a href="#selecting-λ-using-a-cross-validation-set">Selecting λ using a cross validation set</a></li>
</ul></li>
</ul>
</nav>
		    </div>
		    
	    
  		<section class="post">
            <h1 class="post-title">
              <a href="/machinelearning/ex5/">ex5.Regularized Linear Regression and Bias v.s.Variance</a>
            </h1>
            <h3 class="post-subtitle">
            	
            </h3>
            
            	<span class="post-date">
                	<span class="post-date-day"><sup>17</sup></span><span class="post-date-separator">/</span><span class="post-date-month">Nov</span> <span class="post-date-year">2016</span>
            	</span>
            	
            
            	
            

			
			

			

			

            

<p>这个练习其实很简单，基本上都是以前练习的代码，然后让你再重写一遍。这次编程作业的主要作用就是让我们直观的看到不同大小的训练集及不同大小的lambda对拟合效果的影响。具体有以下几个方面：</p>

<ul>
<li>feature太少或者维数过低，会造成高偏差(high bias)，即欠拟合,解决方法是增加feature数，可以是维数增加或者feature数增加（polynomial features)或者降低lambda（正则化项）,feature数增加的前提示增加的feature必须和已有feature是相互独立的，不然没有任何意义，只能增加维数了</li>
<li>类似于上条，如果feature过多或者feature的维数过高，会造成高方差(high variance),即过拟合。解决方法是减少feature数，将不是相互独立的feature去掉，或者降低维数，或者增加正则化项，降低维数对theta参数的影响。还有一个很有用的方法是增加训练集样本，来解决过拟合问题</li>
</ul>

<h2 id="regularized-linear-regression-cost-function-and-gradient">Regularized linear regression cost function and Gradient</h2>

<pre><code>%非矩阵形式
for i = 1 : m
    h = theta(1) * X(i,1) + theta(2) * X(i,2);
    J = J +  (h - y(i))^2 / 2 / m;
end
J = J + lambda / 2 / m * theta(2)^2;
%矩阵形式
J = sum((X * theta - y).^2) / 2 / m + lambda / 2 /m * (sum(theta.^2) - theta(1)^2); 

theta1 = theta;
theta1(1) = 0;
grad = (X' * (X * theta - y))/m + lambda / m * theta1;
</code></pre>

<h2 id="learning-curves">Learning curves</h2>

<pre><code>% ---------------------- Sample Solution ----------------------
for i = 1 : m
    theta = trainLinearReg(X(1:i,:), y(1:i,:), lambda);
    [error_train(i),grad] = linearRegCostFunction(X(1:i,:), y(1:i,:), theta, 0);
    [error_val(i),grad] = linearRegCostFunction(Xval, yval, theta, 0);
end
</code></pre>

<p>在这个步骤中变得很笨，这个步骤是要让我们形式化的看到不同的训练集大小对误差的影响，我在计算训练误差的时候还好，但在计算error_val交叉集误差的时候，也学训练集那样只用Xval和yval的前i个样本，其实是要全部的样本。</p>

<h2 id="polynomial-regression">Polynomial regression</h2>

<pre><code>for i = 1 : p
    X_poly(:,i) = X.^i;
end
</code></pre>

<p>这一部分主要让我们观察不同的feature polynomial对误差的影响，意思是原来的训练集X只有一列，然后我们根据p的值，另外增加p-1列，其中第2列的值为第一列值的平方，第3列的值为第一列值的立方，以此类推</p>

<h2 id="selecting-λ-using-a-cross-validation-set">Selecting λ using a cross validation set</h2>

<pre><code>for i = 1 : length(lambda_vec)
    lambda = lambda_vec(i);
    theta = trainLinearReg(X, y, lambda);
    error_train(i) = linearRegCostFunction(X, y, theta, 0);
    error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);
end
</code></pre>

<p>这一部分就和Learning curves这部分很像，所不同的是Learning curves部分看训练集大小对误差的影响，这次呢，是看不同的lambda λ对误差的影响，训练集和交叉集大小是固定的。</p>

	
			

			

			
				<div class="paging">
					<span class="paging-label">More Reading</span>
					
					<div class="paging-newer">
						<span class="dark-red">Newer</span><span class="decorative-marker">//</span>
						<a class="paging-link" href="/pointcloud/pcl_ransac2/">PCL SampleConsensusMode</a>
		            </div>
		            

					
					<div class="paging-older">
						<span class="dark-red">Older</span><span class="decorative-marker">//</span>
			            <a class="paging-link" href="/machinelearning/ex4/">ex4.Neural Networks Learning</a>
		            </div>
		            
	            </div>
            
          </section>
          
          	
          
        
      <div class="footer">
	<hr class="thin" />
	<div class="pure-menu pure-menu-horizontal pure-menu-open">
		<ul class="footer-menu">
		
		</ul>
	</div>

	<p>&copy; 2017. Matthew Hou All rights reserved.</p>
</div>
    </div>
  </div>
	

	

  
</body>
</html>
