<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MachineLearnings on Hello world!</title>
    <link>https://shiweiHou.github.io/machinelearning/</link>
    <description>Recent content in MachineLearnings on Hello world!</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 09 Nov 2016 10:49:07 +0800</lastBuildDate>
    <atom:link href="https://shiweiHou.github.io/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Neural Networks Learning</title>
      <link>https://shiweihou.github.io/machinelearning/ex4/</link>
      <pubDate>Wed, 09 Nov 2016 10:49:07 +0800</pubDate>
      
      <guid>https://shiweihou.github.io/machinelearning/ex4/</guid>
      <description>

&lt;p&gt;Neural Networks Learning：实现最简单的一个神经网络学习系统，实现反向传播和正向传播，并利用数值计算误差来检测神经网络算法是否可行，或者说cost function是否计算正确。&lt;/p&gt;

&lt;h2 id=&#34;feedforward-and-cost-function&#34;&gt;Feedforward and cost function&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;% You need to return the following variables correctly 
J = 0;
Theta1_grad = zeros(size(Theta1));
Theta2_grad = zeros(size(Theta2));

% ====================== YOUR CODE HERE ======================
% Instructions: You should complete the code by working through the
%               following parts.
%
% Part 1: Feedforward the neural network and return the cost in the
%         variable J. After implementing Part 1, you can verify that your
%         cost function computation is correct by verifying the cost
%         computed in ex4.m
a1 = [ones(m,1) X]; % 5000 * 401
Z2 = a1 * Theta1&#39;;  % 5000 * hidden_layer
a2 = sigmoid(Z2);   % sigmoid
a2 = [ones(size(a2,1),1) a2]; % 5000 * (hidden_layer + 1)
Z3 = a2 * Theta2&#39;;            % 5000 * 10
a3 = sigmoid(Z3);
[max_a3, index] = max(a3,[],2);

I = eye(num_labels); 
Y = zeros(m, num_labels);  % 5000 * 10
for i = 1:m
    Y(i,:) = I(y(i),:);  %  让每一个样例第y(i)列变成1，即将样本输出变成行向量，而不是列向量，每一行为1的列的值即为样本的输出
end
%J = sum(sum((-Y).*log(a3) - (1-Y).*log(1-a3),2))/m;
JJ = 0;
for i = 1 : m   
   JJ = JJ + sum( -1*Y(i,:).* log(a3(i,:)) - (1-Y(i,:)).*log(1-a3(i,:))); %对所有的样本进行相加，每个样本计算J，最后加起来
end
J = JJ / m;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;regularized-cost-function&#34;&gt;Regularized cost function&lt;/h2&gt;

&lt;p&gt;就是在前面计算出来的J的基础上，加上正则化项&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%要去掉theta(1),第一个theta不需要参加
theta1 = Theta1(:,2:size(Theta1,2));
theta2 = Theta2(:,2:size(Theta2,2));
reg = lambda * ( sum ( sum ( theta1.^2) ) + sum ( sum ( theta2.^2) ));
reg = reg / 2 / m;
J = J + reg;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sigmoid-gradient&#34;&gt;Sigmoid gradient&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function g = sigmoidGradient(z)
%SIGMOIDGRADIENT returns the gradient of the sigmoid function
%evaluated at z
%   g = SIGMOIDGRADIENT(z) computes the gradient of the sigmoid function
%   evaluated at z. This should work regardless if z is a matrix or a
%   vector. In particular, if z is a vector or matrix, you should return
%   the gradient for each element.

g = zeros(size(z));
g = sigmoid(z).* (1 - sigmoid(z));
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;backpropagation&#34;&gt;Backpropagation&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sigma3 = a3-Y;
sigma2 = (sigma3*Theta2).*sigmoidGradient([ones(size(Z2, 1), 1) Z2]);
sigma2 = sigma2(:, 2:end);

delta_1 = (sigma2&#39;*a1);
delta_2 = (sigma3&#39;*a2);

p1 = (lambda/m)*[zeros(size(Theta1, 1), 1) Theta1(:, 2:end)];
p2 = (lambda/m)*[zeros(size(Theta2, 1), 1) Theta2(:, 2:end)];
Theta1_grad = delta_1./m + p1;
Theta2_grad = delta_2./m + p2;

grad = [Theta1_grad(:) ; Theta2_grad(:)];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;神经网络算法比较简单，就是计算过程稍微复杂了点，特别是牵涉到里面的矩阵运算的时候，比较麻烦。第一次做的时候感觉无从下手，后来又做了一遍，才感觉稍微懂点。思路都懂，就是写出来比较困难，还需努力。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-class Classification and Neural Networks</title>
      <link>https://shiweihou.github.io/machinelearning/ex3/</link>
      <pubDate>Thu, 03 Nov 2016 19:56:35 +0800</pubDate>
      
      <guid>https://shiweihou.github.io/machinelearning/ex3/</guid>
      <description>

&lt;p&gt;Multi-class Classification&lt;/p&gt;

&lt;p&gt;多分类，其实和前面的二分类，即Logistics regression差不多，只不过因为分类结果有很多个，对于特定的输入，会产生多个输出，在这多个输出里面找到概率最大的那个输出，即为分类答案。&lt;/p&gt;

&lt;h2 id=&#34;lrcostfunction-m&#34;&gt;lrCostFunction.m&lt;/h2&gt;

&lt;p&gt;和第二个练习的一样，就是指导文档里要求我们向量化，即矩阵化求解。前面的练习我们已经做到了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;% 求 J
J1 = sigmoid(X*theta);
J = (0-y).*log(J1) - (1-y).* log (1-J1);
J = sum(J);
J = J / m;
J = J + (lambda / 2 / m) * (sum(theta.^2) - theta(1)^2);
% 求 Gradient 
grad = X&#39; *  (J1 - y ) / m;
tmp = theta;
tmp(1) = 0;
grad = grad + (lambda / m) * tmp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;one-vs-all-classification&#34;&gt;One-vs-all Classification&lt;/h2&gt;

&lt;p&gt;其实多分类也是一个“二分类”问题，只不过每次我们都是选取其中概率最大的那个作为输出“1”，其余的都作为“0”。&lt;strong&gt;oneVsAll.m&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for c = 1 : num_labels
    %yc = (y == c);
    initial_theta = zeros(n + 1, 1);
    options = optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, 50);
    [theta] = ...
         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...
                 initial_theta, options);
    all_theta(c,:) = theta&#39;;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;predictonevsall-m&#34;&gt;predictOneVsAll.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;% max函数，得到tmp矩阵中每一行最大的那个列下标
% 在本题中，列下标即为分类结果
[maximum, index] = max(tmp, [], 2);
% 如果下标是10，我们就用0表示
index(index == 10) = 0;
p = index;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;neural-networks&#34;&gt;Neural Networks&lt;/h2&gt;

&lt;p&gt;这节课Andrew还简单的介绍了下神经网络，并且给出了如何利用神经网络来分类。编程题中Andrew已经给好了训练好的Theta值，只需要我们能根据训练好的Theta值和输入的X值，得到Y值就行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;% You need to return the following variables correctly 
p = zeros(size(X, 1), 1);
%加上第一项1（bias unit)，因为X是m * n的，每个样本的特征在一行，所以加上的就是 m*1的一列，即在每一行的前面加上了个1
X = [ones(m, 1) X];
for i = 1 : m
    XX = X(i:i,:);
    z2 = Theta1 * XX&#39;;
    z2 = sigmoid(z2);
    %row = size(z2,1)
    %加上第一项 1，因为z2是 n*1的，即第i个样本的z2都是单独一列，是个列向量，因此需要加上一行1，即增加一行1
    z22 = [ones(1,1);z2];
    z3 = Theta2 * z22;
    % a3 即为输出结果
    a3 = sigmoid(z3);
    [maxInd, index] = max(a3,[],1);
    if index == 0
        index = 10;
    end
    p(i) = index;
end;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在每一层网络中计算的时候，都要注意要加上一项1作为bias unit&lt;/li&gt;
&lt;li&gt;注意在前面一层输出和Theta积计算完之后，不要忘记做sigmoid操作&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Logistics Regression</title>
      <link>https://shiweihou.github.io/machinelearning/ex2/</link>
      <pubDate>Thu, 03 Nov 2016 18:34:49 +0800</pubDate>
      
      <guid>https://shiweihou.github.io/machinelearning/ex2/</guid>
      <description>

&lt;p&gt;第二次编程作业，逻辑回归，其实可以理解为二分类问题。&lt;/p&gt;

&lt;h2 id=&#34;sigmoid-function&#34;&gt;sigmoid function：&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;% 迭代实现
[row, col] = size(z); 
for i = 1:row
    for j = 1:col
        g(i,j) = 1 / (1 + exp(-z(i,j)));
    end
end

% 非迭代实现
g = 1.0 ./ (1.0 + exp(-z));
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cost-function-and-gradient&#34;&gt;Cost function and Gradient：&lt;/h2&gt;

&lt;p&gt;一开始我是用迭代做的，后来学习了第四课之后，我又回来将迭代的版本改为矩阵版本，看起来确实清晰了很多，以后尽量都用矩阵形式来做（好像这样也更符合matlab的要求）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;% 迭代版本
theta1 = theta&#39;;
[row,col] = size(theta1);
% 求Gradient
for j = 1:col
    J2 = 0;
    for i = 1:m
        XX = X(i:i,:);
        JJ = XX * theta;
        J1 = 1 / (1 + exp(-JJ));
        J2 = J2 + (J1 - y(i))*X(i,j);
    end
    J2 = J2 / m;
    grad(j,1) = J2;
end
% 求 J，cost function
for i = 1:m
    XX = X(i:i,:);
    JJ = XX * theta;
    J1 = 1 / (1 + exp(-JJ));
    J2 = ( -y(i)*log(J1) )  - ( (1-y(i))*log(1-J1) );
    J = J + J2;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面是矩阵版本：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;J1 = sigmoid(X*theta);
% 求 J， cost function
J2 = -(y&#39;) * log(J1);
J3 = (1 - y&#39;) * log( 1 - J1);
J = J2 - J3;
J = J / m;
% 求 Gradient
g1 = J1 - y;
g2 = X&#39; * g1;
grad = g2 / m;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;regularized-logistic-regression&#34;&gt;Regularized logistic regression：&lt;/h2&gt;

&lt;p&gt;为什么要用到正则化呢？是因为有时候特征项我们选取的过多，有时候会出现过拟合问题。那么，一旦出现过拟合问题的时候，就会发生训练模型对训练集拟合非常好，但对新的数据就拟合偏差很大。这个时候，我们就需要用正则化项来惩罚参数，防止其过大，从而避免过拟合问题。同样，我一开始写的是迭代过程，后来又被我改成矩阵形式了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;theta1 = theta&#39;;
[row,col] = size(theta1);
% 求 Gradient
for j = 1:col
    J2 = 0;
    for i = 1:m
        XX = X(i:i,:);
        JJ = XX * theta;
        J1 = 1 / (1 + exp(-JJ));
        J2 = J2 + (J1 - y(i))*X(i,j);
    end
    J2 = J2 / m;
    %对第一个参数 theta0 不进行正则化
    if j &amp;gt;= 2
        grad(j,1) = J2 + (lambda / m ) * theta(j);
    else
        grad(j,1) = J2;
    end
end
%求 J， cost function
for i = 1:m
    XX = X(i:i,:);
    JJ = XX * theta;
    J1 = 1 / (1 + exp(-JJ));
    J2 = ( -y(i)*log(J1) )  - ( (1-y(i))*log(1-J1) );
    J = J + J2;
end
% 对第一个参数 theta0 不进行正则化
J = J / m;
J = J + (lambda / 2 / m ) * ( sum(theta.^2) - theta(1)^2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;矩阵形式，和上面的logistics regression矩阵形式差不多，只需要注意不要对第一项进行处理即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;% 求 J
J1 = sigmoid(X*theta);
J2 = -(y&#39;) * log(J1);
J3 = (1 - y&#39;) * log( 1 - J1);
J = J2 - J3;
J = J / m;
J = J + (lambda / 2 / m ) * ( sum(theta.^2) - theta(1)^2);
% 求 Gradient
g1 = J1 - y;
g2 = X&#39; * g1;
grad = g2 / m;
grad = grad + (lambda / m ) * theta;
grad(1) = grad(1) - (lambda / m ) * theta(1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对了，还有个predict函数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i = 1 : m
    XX = X(i:i,:);
    pp = sigmoid(XX*theta);
    if pp &amp;gt;= 0.5
        p(i) = 1;
    else
        p(i) = 0;
    end
end
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>线性回归</title>
      <link>https://shiweihou.github.io/machinelearning/ex1/</link>
      <pubDate>Sun, 30 Oct 2016 16:10:31 +0800</pubDate>
      
      <guid>https://shiweihou.github.io/machinelearning/ex1/</guid>
      <description>

&lt;p&gt;从今天开始，开始记录学习机器学习学习过程。目前的学习方法是根据&lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;Coursera&lt;/a&gt;上Andrew Ng大牛的机器学习课程，据说是同名的斯坦福大学公开课的简化版本，仅介绍基本原理及提供配套的练习，非常适合新手入门。强烈推荐大家去看下视频，讲解的很详细，而且还有配套的演示过程，非常适合新手。&lt;/p&gt;

&lt;p&gt;有关线性回归的具体内容我就不多说了，网上例子有很多，教程有很多，我只谈下在学习过程中自己遇到的一些问题及看法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在学习过程中，参数需要同时更新，不能用更新好的参数去更新下一个参数，例如不能用更新好的 theta0 去更新 theta1.&lt;/li&gt;
&lt;li&gt;如果数据特征变化尺度过大，例如x1在[1,10]范围内，而x2就在[10000,10000000]范围内，就需要进行特征缩放，重新缩放特征的范围到[0, 1]或[-1, 1]。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;顺便贴下第一课的课后作业的答案：&lt;/p&gt;

&lt;h2 id=&#34;computecost-m&#34;&gt;computeCost.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function J = computeCost(X, y, theta)
%COMPUTECOST Compute cost for linear regression
%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the
%   parameter for linear regression to fit the data points in X and y
% Initialize some useful values
m = length(y); % number of training examples
% You need to return the following variables correctly 
J = 0;
% ====================== YOUR CODE HERE ======================
% Instructions: Compute the cost of a particular choice of theta
%               You should set J to the cost.
for i = 1 : m,
J = J + (theta(1) * X(i,1) + theta(2) * X(i,2) - y(i)) ^ 2;
end
J = J / (2 * m);
% =========================================================================
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;computecostmulti-m&#34;&gt;computeCostMulti.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function J = computeCostMulti(X, y, theta)
%COMPUTECOSTMULTI Compute cost for linear regression with multiple variables
%   J = COMPUTECOSTMULTI(X, y, theta) computes the cost of using theta as the
%   parameter for linear regression to fit the data points in X and y
% Initialize some useful values
m = length(y); % number of training examples
% You need to return the following variables correctly 
J = 0;
% ====================== YOUR CODE HERE ======================
% Instructions: Compute the cost of a particular choice of theta
%               You should set J to the cost.
for i = 1 : m 
    JJ = 0;
    for j = 1 : size(theta,1)
        JJ = JJ + theta(j) * X(i,j);
    end
    JJ = JJ - y(i);
    J = J + JJ ^ 2;
end
J = J / (2 * m);
% =========================================================================
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;featurenormalize-m&#34;&gt;featureNormalize.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function [X_norm, mu, sigma] = featureNormalize(X)
%FEATURENORMALIZE Normalizes the features in X 
%   FEATURENORMALIZE(X) returns a normalized version of X where
%   the mean value of each feature is 0 and the standard deviation
%   is 1. This is often a good preprocessing step to do when
%   working with learning algorithms.
% You need to set these values correctly
X_norm = X;
mu = zeros(1, size(X, 2));
sigma = zeros(1, size(X, 2));
% ====================== YOUR CODE HERE ======================
% Instructions: First, for each feature dimension, compute the mean
%               of the feature and subtract it from the dataset,
%               storing the mean value in mu. Next, compute the 
%               standard deviation of each feature and divide
%               each feature by it&#39;s standard deviation, storing
%               the standard deviation in sigma. 
%
%               Note that X is a matrix where each column is a 
%               feature and each row is an example. You need 
%               to perform the normalization separately for 
%               each feature. 
%
% Hint: You might find the &#39;mean&#39; and &#39;std&#39; functions useful.
%       
avg = mean(X);
piancha = std(X);
for row = 1 : size(X,1)
    for col = 1 : size(X,2)
        X_norm(row,col) = (X(row,col) - avg(col)) / piancha(col);
    end
end
mu = avg;
sigma = piancha;
% ============================================================
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gradientdescent-m&#34;&gt;gradientDescent.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)
%GRADIENTDESCENT Performs gradient descent to learn theta
%   theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by 
%   taking num_iters gradient steps with learning rate alpha

% Initialize some useful values
m = length(y); % number of training examples
J_history = zeros(num_iters, 1);

for iter = 1:num_iters
% ====================== YOUR CODE HERE ======================
% Instructions: Perform a single gradient step on the parameter vector
%               theta. 
%
% Hint: While debugging, it can be useful to print out the values
%       of the cost function (computeCost) and gradient here.
%
% ============================================================
% Save the cost J in every iteration    
    J_history(iter) = computeCost(X, y, theta);
    theta1 = theta;
    for j = 1:2
    J = 0;
    for i = 1 : m
        J = J + (theta(1) * X(i,1) + theta(2) * X(i,2) - y(i)) * X(i,j);
    end
    theta1(j) = theta(j) - alpha * J / m;
    end
    theta = theta1;
end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gradientdescentmulti-m&#34;&gt;gradientDescentMulti.m&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)
%GRADIENTDESCENT Performs gradient descent to learn theta
%   theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by 
%   taking num_iters gradient steps with learning rate alpha

% Initialize some useful values
m = length(y); % number of training examples
J_history = zeros(num_iters, 1);

for iter = 1:num_iters
% ====================== YOUR CODE HERE ======================
% Instructions: Perform a single gradient step on the parameter vector
%               theta. 
%
% Hint: While debugging, it can be useful to print out the values
%       of the cost function (computeCost) and gradient here.
%
% ============================================================
% Save the cost J in every iteration    
    J_history(iter) = computeCost(X, y, theta);
    theta1 = theta;
    for j = 1:2
    J = 0;
    for i = 1 : m
        J = J + (theta(1) * X(i,1) + theta(2) * X(i,2) - y(i)) * X(i,j);
    end
    theta1(j) = theta(j) - alpha * J / m;
    end
    theta = theta1;
end

end
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>